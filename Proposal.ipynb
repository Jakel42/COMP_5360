{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265fd45b",
   "metadata": {},
   "source": [
    "## Basic Info\n",
    "\n",
    "SlamStats Analytics <br>\n",
    "\n",
    "Vincent Funtanilla - u1282199@utah.edu, u1282199 <br>\n",
    "\n",
    "Jacob Layton - jake.layton@utah.edu, u1312858 <br>\n",
    "\n",
    "John Chae- u1285738@utah.edu, u1285738 <br>\n",
    "\n",
    "## Background and Motivation <br>\n",
    " \n",
    "Our motivation for undertaking this  project stems from a passion and curiosity for the game of basketball. By delving into player performances, strategies, and game outcomes, we hope to provide a valuable resource for basketball enthusiasts and enhance the overall fan experience. We want to contribute positively to the basketball community, offering valuable insights for analysts, coaches, and fans alike. We also see this project as an opportunity for skill development, allowing us to apply and refine our data science skills in a real-world context. Ultimately, our goal is to bring innovation to sports analytics, fostering a deeper appreciation for the game we love.\n",
    "\n",
    "## Project Objectives <br>\n",
    "\n",
    "There are three questions we want to answer;<br>\n",
    "- Who will be the 2024 MVP?<br>\n",
    "- Who will be the 2024 defensive player of the year?<br>\n",
    "- Which team will win the 2024 NBA Finals?<br>\n",
    "    \n",
    "We want to create a model that can predict not only this years finals and award winners, but also identify what the most important statistics are in prediciting them and how effective they are at it. This will help us gain a lot of insight into what these statistics mean and give us a better understanding of linear regression models \n",
    "    \n",
    "## Data Description and Acquisition\n",
    "\n",
    "We will be collecting data from https://www.basketball-reference.com/. Basketball Reference is an online basketball encyclopedia that contains all relevant basketball statistics. We will mainly focus on collecting player statistics as these are relevant to the questions that we want to answer. This website does not allow data scraping but all data is available to download as Excel spreadsheets. To obtain the data we will download the Excel spreadsheet containing the data of interest from Basketball Reference and then we will save the spreadsheet as a CSV file which we can open in Jupyter Notebook. Figure 1 displays what the data frame looks like when the MVP player data from the following link has been successfully extracted in Jupyter Notebook. https://www.basketball-reference.com/awards/mvp.html. \n",
    "\n",
    "\n",
    "<img src=\"data_frame.png\" alt=\"dataframe\" style=\"max-width: 100%; height: auto;\"/>\n",
    "\n",
    "Figure 1: Data frame containing player statistics of the previous MVP award winners\n",
    "\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "One main ethical implication of our analyses is related to gambling. While our project aims to provide valuable insights into basketball dynamics, we acknowledge the potential risk of individuals excessively gambling based on our findings. It is important that we approach our work with a sense of responsibility, emphasizing the importance of using data-driven insights for informed decision-making rather than irresponsible gambling behavior. We can also promote responsible engagement with our analyses and advocate for measures to mitigate the risks associated with problem gambling within the context of sports betting.<br>\n",
    "\n",
    "Itâ€™s also crucial to consider the potential impact of our analyses on fan engagement and player welfare. While we aim to foster constructive dialogue among fans, we should avoid promoting negative behaviors or attitudes that could harm the mental well-being of players. We want to uphold the integrity of the game and the welfare of those involved, including players, teams, and fans.\n",
    "\n",
    "## Data Cleaning and Processing\n",
    "\n",
    "We do not plan to do substantial data extraction or cleanup. As can be seen in Figure 1 many of the titles are in the first row of the data frame instead of above so this will need to be adjusted. From the data set, we are looking to extract the statistics relevant to the player's performance. Due to this, we will need to remove the extraneous data from the set such as the league that the players play in. We will write a function that appropriately cleans the data so that each set of data can be easily cleaned. <br>\n",
    "\n",
    "## Exploratory Analysis\n",
    "\n",
    "We are attempting to predict various outcomes of the 2024 NBA season. To help us do this we will start with creating a heat map in order to visualize a correlation matrix. This will help us determine which statistics are relevant in predicting the desired outcomes. We will also plot a scatter plot matrix to help us visualize the relationship between pairs of variables. This will further aid in understanding correlations and patterns within the data. <br>\n",
    "\n",
    "## Analysis Methodolog\n",
    "\n",
    "First, we will extract and clean the NBA data set and then use a basic visualization tool to visualize the data set. Then we would use statistical analysis and find which variable is the best predictor for our questions Since this is time series data, we will choose one of the predictive model libraries from Python and use it to answer our questions. Then we would move on to answer our question on which variables are best in predicting the MVP player of the year, defensive player of the year, and the winner of the NBA.\n",
    "\n",
    "## Project Schedule\n",
    "\n",
    "For the next week, we will collect, extract, load, and clean the data set. The following week we will spend our time visualizing and analyzing our data set, seeing if there are any discrepancies or trends. After all of that, we will move on to our statistical analysis and machine learning by implementing predictive models. Once that is done we will organize everything and write our reports and present our findings. For the next week, we will collect, extract, load, and clean the data set. The following week we will spend our time visualizing and analyzing our data set, seeing if there are any discrepancies or trends. After all of that, we will move on to our statistical analysis and machine learning by implementing predictive models. Once that is done we will organize everything and write our reports and present our findings. <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
